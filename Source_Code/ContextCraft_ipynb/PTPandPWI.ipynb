{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M83YSj1wsuFI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "# Sample data\n",
        "data = pd.read_csv('/content/drive/MyDrive/Method/EnglishMethod/Java_Train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc-7glH3eusA",
        "outputId": "c86e7e75-338a-49a3-cae8-9264cfbb89ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Functional Description  \\\n",
            "0                         get the role of this object      \n",
            "1                        get the state of this object      \n",
            "2      called by the browser or applet viewer to info...   \n",
            "3      gets the accessible context associated with th...   \n",
            "4      determines this applet ' s context , which all...   \n",
            "...                                                  ...   \n",
            "17734  allows an interceptor to query the information...   \n",
            "17735  this operation is invoked when the orb receive...   \n",
            "17736  returns the object id identifying the object i...   \n",
            "17737  returns reference to the poa implementing the ...   \n",
            "17738  receives requests issued to any corba object i...   \n",
            "\n",
            "                       Method Name  \n",
            "0              get accessible role  \n",
            "1         get accessible state set  \n",
            "2                          destroy  \n",
            "3           get accessible context  \n",
            "4               get applet context  \n",
            "...                            ...  \n",
            "17734                   send other  \n",
            "17735              unknown adapter  \n",
            "17736                get object id  \n",
            "17737                      get poa  \n",
            "17738                       invoke  \n",
            "\n",
            "[17739 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZUxRtFADb8Q",
        "outputId": "038b5c22-8cc0-429c-879c-f1bd87fce823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts.\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "# Initialize the WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def to_base_form(token):\n",
        "    return lemmatizer.lemmatize(token, get_wordnet_pos(token))"
      ],
      "metadata": {
        "id": "Rth6QdqoDeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "# Import defaultdict from the collections module\n",
        "from collections import defaultdict\n",
        "import inflect\n",
        "\n",
        "# Initialize inflect engine\n",
        "p = inflect.engine()\n",
        "# Accumulate counts\n",
        "position_counts = defaultdict(lambda: defaultdict(int))\n",
        "fd_token_occurrences = defaultdict(int)\n",
        "# Function to extract tokens\n",
        "def extract_tokens(text):\n",
        "    # Convert text to lowercase and split into tokens\n",
        "    tokens = text.lower().split()\n",
        "    # Convert plural tokens to singular, if applicable, and verbs to base form\n",
        "    processed_tokens = []\n",
        "    for token in tokens:\n",
        "        singular_token = p.singular_noun(token)\n",
        "        if singular_token:\n",
        "            # If a singular form is returned, use it\n",
        "            token = singular_token\n",
        "        # Lemmatize the token (noun or verb to base form)\n",
        "        base_form_token = lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
        "        processed_tokens.append(base_form_token)\n",
        "    return processed_tokens\n",
        "\n",
        "# Accumulate counts\n",
        "position_counts = defaultdict(lambda: defaultdict(int))\n",
        "fd_token_occurrences = defaultdict(int)\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    fd_tokens = extract_tokens(row['Functional Description'])\n",
        "    mn_tokens = extract_tokens(row['Method Name'])\n",
        "\n",
        "    for fd_token in fd_tokens:\n",
        "        fd_token_occurrences[fd_token] += 1\n",
        "        if fd_token in mn_tokens:\n",
        "            index = mn_tokens.index(fd_token)\n",
        "            if index == 0:\n",
        "                position_counts[fd_token]['prefix'] += 1\n",
        "            elif index == len(mn_tokens) - 1:\n",
        "                position_counts[fd_token]['suffix'] += 1\n",
        "            else:\n",
        "                position_counts[fd_token]['infix'] += 1\n",
        "\n",
        "# Calculate conditional probabilities\n",
        "position_probabilities = defaultdict(dict)\n",
        "for token, positions in position_counts.items():\n",
        "    total = fd_token_occurrences[token]\n",
        "    for position in ['prefix', 'infix', 'suffix']:\n",
        "        position_probabilities[token][position] = positions[position] / total\n",
        "\n",
        "# Creating a DataFrame to display results\n",
        "result_data = {\n",
        "    'Token': [],\n",
        "    'Prefix Probability': [],\n",
        "    'Infix Probability': [],\n",
        "    'Suffix Probability': []\n",
        "}\n",
        "\n",
        "for token, probabilities in position_probabilities.items():\n",
        "    result_data['Token'].append(token)\n",
        "    result_data['Prefix Probability'].append(probabilities.get('prefix', 0))\n",
        "    result_data['Infix Probability'].append(probabilities.get('infix', 0))\n",
        "    result_data['Suffix Probability'].append(probabilities.get('suffix', 0))\n",
        "\n",
        "probability_df = pd.DataFrame(result_data)\n",
        "\n",
        "print(probability_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsDjv5P_KGzJ",
        "outputId": "77e5b230-4d23-445f-e0a2-1b56b0065e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Token  Prefix Probability  Infix Probability  Suffix Probability\n",
            "0             get            0.875530           0.001414            0.000000\n",
            "1            role            0.000000           0.371429            0.314286\n",
            "2           state            0.012712           0.097458            0.165254\n",
            "3         destroy            0.875000           0.000000            0.000000\n",
            "4      accessible            0.000000           0.833333            0.013333\n",
            "...           ...                 ...                ...                 ...\n",
            "1668  interceptor            0.000000           0.000000            0.230769\n",
            "1669        codec            0.250000           0.000000            0.000000\n",
            "1670       expect            0.000000           0.000000            0.034483\n",
            "1671         most            0.000000           0.022727            0.000000\n",
            "1672          poa            0.000000           0.000000            0.500000\n",
            "\n",
            "[1673 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the filename\n",
        "filename = 'pp.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "probability_df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "Mi-0MKPmGfDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import inflect\n",
        "\n",
        "# Initialize inflect engine\n",
        "p = inflect.engine()\n",
        "\n",
        "# Function to extract tokens and convert plurals to singular\n",
        "def extract_tokens(text):\n",
        "    # Convert text to lowercase and split into tokens\n",
        "    tokens = text.lower().split()\n",
        "    # Convert plural tokens to singular, if applicable, and verbs to base form\n",
        "    processed_tokens = []\n",
        "    for token in tokens:\n",
        "        singular_token = p.singular_noun(token)\n",
        "        if singular_token:\n",
        "            # If a singular form is returned, use it\n",
        "            token = singular_token\n",
        "        # Lemmatize the token (noun or verb to base form)\n",
        "        base_form_token = lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
        "        processed_tokens.append(base_form_token)\n",
        "    return processed_tokens\n",
        "# Your functional description\n",
        "functional_description = \"sets the background color of this object\"\n",
        "\n",
        "# Tokenize the functional description\n",
        "tokens = extract_tokens(functional_description)\n",
        "\n",
        "# Variables to keep track of top probabilities and corresponding tokens\n",
        "top_prefix = ('', 0)  # (token, probability)\n",
        "top_infix = ('', 0)\n",
        "top_suffix = ('', 0)\n",
        "\n",
        "# Find the most probable position for each token\n",
        "for token in tokens:\n",
        "    if token in probability_df['Token'].values:\n",
        "        row = probability_df[probability_df['Token'] == token]\n",
        "        # Extract probabilities\n",
        "        prefix_prob = row['Prefix Probability'].values[0] * 100\n",
        "        infix_prob = row['Infix Probability'].values[0] * 100\n",
        "        suffix_prob = row['Suffix Probability'].values[0] * 100\n",
        "\n",
        "        # Update top tokens if current token has higher probability and meets the threshold\n",
        "        if prefix_prob > top_prefix[1] and prefix_prob >= 50:\n",
        "            top_prefix = (token, prefix_prob)\n",
        "        if infix_prob > top_infix[1] and infix_prob >= 50:\n",
        "            top_infix = (token, infix_prob)\n",
        "        if suffix_prob > top_suffix[1] and suffix_prob >= 50:\n",
        "            top_suffix = (token, suffix_prob)\n",
        "\n",
        "# Format final output with probabilities\n",
        "output = f\"In this description, '{top_prefix[0]}' is most likely to be the prefix with a probability of {top_prefix[1]:.2f}%\"\n",
        "if top_infix[0]:\n",
        "    output += f\", '{top_infix[0]}' the infix with a probability of {top_infix[1]:.2f}%\"\n",
        "if top_suffix[0]:\n",
        "    output += f\", and '{top_suffix[0]}' the suffix with a probability of {top_suffix[1]:.2f}%\"\n",
        "output += \" in the method name.\"\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i12sjRj6MzMQ",
        "outputId": "d6d275ff-ae55-4942-8e08-5400ac653d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this description, 'set' is most likely to be the prefix with a probability of 60.20%, and 'background' the suffix with a probability of 70.91% in the method name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import inflect\n",
        "import re\n",
        "\n",
        "# Initialize inflect engine for singularization\n",
        "p = inflect.engine()\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Tokenize and preprocess descriptions\n",
        "def preprocess_and_tokenize(text):\n",
        "     # Convert text to lowercase and split into tokens\n",
        "    tokens = text.lower().split()\n",
        "    # Convert plural tokens to singular, if applicable, and verbs to base form\n",
        "    processed_tokens = []\n",
        "    for token in tokens:\n",
        "        singular_token = p.singular_noun(token)\n",
        "        if singular_token:\n",
        "            # If a singular form is returned, use it\n",
        "            token = singular_token\n",
        "        # Lemmatize the token (noun or verb to base form)\n",
        "        base_form_token = lemmatizer.lemmatize(token, get_wordnet_pos(token))\n",
        "        processed_tokens.append(base_form_token)\n",
        "    return processed_tokens\n",
        "\n",
        "# Process each functional description\n",
        "def find_top_tokens(description):\n",
        "    tokens = preprocess_and_tokenize(description)\n",
        "    top_prefix = top_infix = top_suffix = (None, 0)  # Initialize with None and 0 probability\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in probability_df['Token'].values:\n",
        "            token_data = probability_df[probability_df['Token'] == token]\n",
        "            # Extract probabilities and check if they are the highest found so far above the threshold\n",
        "            prefix_prob = token_data['Prefix Probability'].values[0]\n",
        "            infix_prob = token_data['Infix Probability'].values[0]\n",
        "            suffix_prob = token_data['Suffix Probability'].values[0]\n",
        "\n",
        "            if prefix_prob >= 0.5 and (top_prefix[1] is None or prefix_prob > top_prefix[1]):\n",
        "                top_prefix = (token, prefix_prob)\n",
        "            if infix_prob >= 0.5 and (top_infix[1] is None or infix_prob > top_infix[1]):\n",
        "                top_infix = (token, infix_prob)\n",
        "            if suffix_prob >= 0.5 and (top_suffix[1] is None or suffix_prob > top_suffix[1]):\n",
        "                top_suffix = (token, suffix_prob)\n",
        "\n",
        "    return (top_prefix[0], top_infix[0], top_suffix[0]), (top_prefix[1], top_infix[1], top_suffix[1])\n",
        "\n",
        "# Apply the function to each description and unpack results into new columns\n",
        "results = df['Functional Description'].apply(find_top_tokens)\n",
        "df['Prefix'], df['Infix'], df['Suffix'] = zip(*results.apply(lambda x: x[0]))\n",
        "df['Prefix Probability'], df['Infix Probability'], df['Suffix Probability'] = zip(*results.apply(lambda x: x[1]))\n",
        "# Show updated DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgG6KZ4H_i-H",
        "outputId": "ef4bc05c-900e-4c03-b437-8751ff69a5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  Functional Description  \\\n",
            "0                         get the role of this object      \n",
            "1                        get the state of this object      \n",
            "2      called by the browser or applet viewer to info...   \n",
            "3      gets the accessible context associated with th...   \n",
            "4      determines this applet ' s context , which all...   \n",
            "...                                                  ...   \n",
            "17734  allows an interceptor to query the information...   \n",
            "17735  this operation is invoked when the orb receive...   \n",
            "17736  returns the object id identifying the object i...   \n",
            "17737  returns reference to the poa implementing the ...   \n",
            "17738  receives requests issued to any corba object i...   \n",
            "\n",
            "                       Method Name   Prefix       Infix Suffix  \\\n",
            "0              get accessible role      get        None   None   \n",
            "1         get accessible state set      get        None   None   \n",
            "2                          destroy  destroy        None   None   \n",
            "3           get accessible context      get  accessible   None   \n",
            "4               get applet context     None        None   None   \n",
            "...                            ...      ...         ...    ...   \n",
            "17734                   send other     None        None   None   \n",
            "17735              unknown adapter     None        None    poa   \n",
            "17736                get object id     None        None   None   \n",
            "17737                      get poa     None        None    poa   \n",
            "17738                       invoke     None        None   None   \n",
            "\n",
            "       Prefix Probability  Infix Probability  Suffix Probability  \n",
            "0                 0.87553           0.000000                 0.0  \n",
            "1                 0.87553           0.000000                 0.0  \n",
            "2                 0.87500           0.000000                 0.0  \n",
            "3                 0.87553           0.833333                 0.0  \n",
            "4                 0.00000           0.000000                 0.0  \n",
            "...                   ...                ...                 ...  \n",
            "17734             0.00000           0.000000                 0.0  \n",
            "17735             0.00000           0.000000                 0.5  \n",
            "17736             0.00000           0.000000                 0.0  \n",
            "17737             0.00000           0.000000                 0.5  \n",
            "17738             0.00000           0.000000                 0.0  \n",
            "\n",
            "[17739 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the filename\n",
        "filename = 'Engdataset.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "4rlKs_DvAW_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "udQ6v2hOjfyQ",
        "outputId": "457b48d2-e644-4572-9f2d-524b1d396594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Functional Description  \\\n",
              "0                     get the role of this object      \n",
              "1                    get the state of this object      \n",
              "2  called by the browser or applet viewer to info...   \n",
              "3  gets the accessible context associated with th...   \n",
              "4  determines this applet ' s context , which all...   \n",
              "\n",
              "                   Method Name   Prefix       Infix Suffix  \\\n",
              "0          get accessible role      get        None   None   \n",
              "1     get accessible state set      get        None   None   \n",
              "2                      destroy  destroy        None   None   \n",
              "3       get accessible context      get  accessible   None   \n",
              "4           get applet context     None        None   None   \n",
              "\n",
              "   Prefix Probability  Infix Probability  Suffix Probability  \n",
              "0             0.87553           0.000000                 0.0  \n",
              "1             0.87553           0.000000                 0.0  \n",
              "2             0.87500           0.000000                 0.0  \n",
              "3             0.87553           0.833333                 0.0  \n",
              "4             0.00000           0.000000                 0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11ac1ed1-ce96-4f82-b659-386781b867ad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Functional Description</th>\n",
              "      <th>Method Name</th>\n",
              "      <th>Prefix</th>\n",
              "      <th>Infix</th>\n",
              "      <th>Suffix</th>\n",
              "      <th>Prefix Probability</th>\n",
              "      <th>Infix Probability</th>\n",
              "      <th>Suffix Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get the role of this object</td>\n",
              "      <td>get accessible role</td>\n",
              "      <td>get</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.87553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>get the state of this object</td>\n",
              "      <td>get accessible state set</td>\n",
              "      <td>get</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.87553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>called by the browser or applet viewer to info...</td>\n",
              "      <td>destroy</td>\n",
              "      <td>destroy</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gets the accessible context associated with th...</td>\n",
              "      <td>get accessible context</td>\n",
              "      <td>get</td>\n",
              "      <td>accessible</td>\n",
              "      <td>None</td>\n",
              "      <td>0.87553</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>determines this applet ' s context , which all...</td>\n",
              "      <td>get applet context</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11ac1ed1-ce96-4f82-b659-386781b867ad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11ac1ed1-ce96-4f82-b659-386781b867ad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11ac1ed1-ce96-4f82-b659-386781b867ad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d88326c-93a2-4775-9bc1-bfae1743e701\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d88326c-93a2-4775-9bc1-bfae1743e701')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d88326c-93a2-4775-9bc1-bfae1743e701 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17739,\n  \"fields\": [\n    {\n      \"column\": \"Functional Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17340,\n        \"samples\": [\n          \"sets the font of this component   \",\n          \"visits an unknown kind of type   \",\n          \"returns an array length 1 containing the currently selected item   \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Method Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8777,\n        \"samples\": [\n          \"   add owner\",\n          \"   get attribute\",\n          \"   is xi nclude aware\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prefix\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 103,\n        \"samples\": [\n          \"reconvert\",\n          \"tertiary\",\n          \"export\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Infix\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          \"lower\",\n          \"boot\",\n          \"viewport\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Suffix\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 220,\n        \"samples\": [\n          \"caption\",\n          \"ctx\",\n          \"dirty\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prefix Probability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3375392771220944,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          0.5641025641025641,\n          0.6176470588235294,\n          0.8157894736842105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Infix Probability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18840720879666667,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          0.6285714285714286,\n          0.9375,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Suffix Probability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21258439644574392,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          0.5652173913043478,\n          0.5373134328358209,\n          0.8181818181818182\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_token_details(dataframe, description):\n",
        "    # Ensure the DataFrame and description are prepared for matching\n",
        "    description = description.strip().lower()\n",
        "    dataframe['Functional Description'] = dataframe['Functional Description'].astype(str).str.strip().str.lower()\n",
        "\n",
        "    # Find the matching row\n",
        "    row = dataframe[dataframe['Functional Description'] == description]\n",
        "\n",
        "    if not row.empty:\n",
        "        # Extract and format the output\n",
        "        output = \"In this description, \"\n",
        "        details = []\n",
        "\n",
        "        # Check and format prefix\n",
        "        if pd.notna(row['Prefix'].values[0]):\n",
        "            prefix = row['Prefix'].values[0]\n",
        "            prefix_prob = row['Prefix Probability'].values[0] * 100  # Convert probability to percentage\n",
        "            details.append(f\"'{prefix}' is most likely to be the prefix with a probability of {prefix_prob:.2f}%\")\n",
        "\n",
        "        # Check and format infix\n",
        "        if pd.notna(row['Infix'].values[0]):\n",
        "            infix = row['Infix'].values[0]\n",
        "            infix_prob = row['Infix Probability'].values[0] * 100  # Convert probability to percentage\n",
        "            details.append(f\"'{infix}' the infix with a probability of {infix_prob:.2f}%\")\n",
        "\n",
        "        # Check and format suffix\n",
        "        if pd.notna(row['Suffix'].values[0]):\n",
        "            suffix = row['Suffix'].values[0]\n",
        "            suffix_prob = row['Suffix Probability'].values[0] * 100  # Convert probability to percentage\n",
        "            details.append(f\"and '{suffix}' the suffix with a probability of {suffix_prob:.2f}%\")\n",
        "\n",
        "        output += \", \".join(details) + \" in the method name.\"\n",
        "        return output\n",
        "    else:\n",
        "        return \"Description not found in DataFrame\"\n",
        "\n",
        "\n",
        "# Usage example\n",
        "description = \"get the state of this object\"\n",
        "result = find_token_details(df, description)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJEWAFYTtqqo",
        "outputId": "6fd2642a-fc48-45e2-eb49-c5b88b8d3ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this description, 'get' is most likely to be the prefix with a probability of 87.55% in the method name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pymikP3Ucq7",
        "outputId": "e0ea6846-7372-40dc-eb86-d71910f7f236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zfJTho89GEI",
        "outputId": "5b27e010-27a6-4026-8de1-f698b8654756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "\n",
        "def get_token_embeddings(text):\n",
        "    \"\"\"Generates BERT embeddings for each token in the input text.\"\"\"\n",
        "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        output = model(**encoded_input)\n",
        "    embeddings = output.hidden_states[-1].squeeze(0)  # Get the embeddings from the last layer\n",
        "    return embeddings, encoded_input['input_ids']\n",
        "\n",
        "def find_best_description_tokens(method_name, description):\n",
        "    \"\"\"Finds the description token with the highest similarity score for each method name token.\"\"\"\n",
        "    name_embeddings, name_ids = get_token_embeddings(method_name)\n",
        "    desc_embeddings, desc_ids = get_token_embeddings(description)\n",
        "\n",
        "    name_tokens = [tokenizer.decode([token_id]).strip() for token_id in name_ids[0]]\n",
        "    desc_tokens = [tokenizer.decode([token_id]).strip() for token_id in desc_ids[0]]\n",
        "\n",
        "    best_matches = {}\n",
        "\n",
        "    # Iterate over each token in the method name\n",
        "    for i, (name_embed, name_token) in enumerate(zip(name_embeddings, name_tokens)):\n",
        "        if name_token in ['[CLS]', '[SEP]']:\n",
        "            continue\n",
        "        highest_score = -1\n",
        "        best_token = None\n",
        "        # Compare with each token in the description\n",
        "        for j, (desc_embed, desc_token) in enumerate(zip(desc_embeddings, desc_tokens)):\n",
        "            if desc_token in ['[CLS]', '[SEP]'] or desc_token.startswith('##'):\n",
        "                continue\n",
        "            similarity = 1 - cosine(name_embed, desc_embed)\n",
        "            if similarity > highest_score:\n",
        "                highest_score = similarity\n",
        "                best_token = desc_token\n",
        "        best_matches[name_token] = (best_token, highest_score)\n",
        "\n",
        "    return best_matches"
      ],
      "metadata": {
        "id": "IOlRSD4F58Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "method_name = \"clone\"\n",
        "description = \"create a copy of this object \"\n",
        "result = find_best_description_tokens(method_name, description)\n",
        "print(result)\n",
        "method_name = \"check access\"\n",
        "description = \"Verify if the current user has the authority to access the requested resource.\"\n",
        "result = find_best_description_tokens(method_name, description)\n",
        "print(result)\n",
        "method_name = \"save settings\"\n",
        "description = \"Persist the user's configuration preferences to ensure changes are not lost.\"\n",
        "result = find_best_description_tokens(method_name, description)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SruLjnQ-Q5x",
        "outputId": "b9ca3fa9-0798-4477-e863-a7e9ecb66ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'clone': ('object', 0.417935848236084)}\n",
            "{'check': ('verify', 0.6228334903717041), 'access': ('access', 0.5798786282539368)}\n",
            "{'save': ('user', 0.5641632080078125), 'settings': ('preferences', 0.5901214480400085)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Pivot'] = df.apply(lambda row: find_best_description_tokens(row['Method Name'], row['Functional Description']), axis=1)\n",
        "# Specify the filename\n",
        "filename = 'Processed_dataset.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "39VGh2ML914j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Create a function to generate the description for each row\n",
        "def generate_description(row):\n",
        "    return (\n",
        "        f'1) Functional Description: \"{row[\"Functional Description\"]}\" '\n",
        "        f'Method Name: \"{row[\"Mname\"]}\". '\n",
        "        f'In this example, \"{row[\"Prefix\"]}\" is most likely to be the prefix with a probability of {row[\"Prefix Probability\"]:.5f}%, '\n",
        "        f'\"{row[\"Infix\"]}\" is the Infix with a probability of {row[\"Infix Probability\"]:.5f}%, and '\n",
        "        f'\"{row[\"Suffix\"]}\" is the Suffix with a probability of {row[\"Suffix Probability\"]:.5f}% in the method name. '\n",
        "        f'More on, semantic similarity between description and method token is \"{row[\"Pivot\"]}\". '\n",
        "        f'The base LLM predicted the method name \"{row[\"Predicted_Method\"]}\", which has an edit distance score of {row[\"Edit_Score\"]} '\n",
        "        f'compared to the ground truth \"{row[\"Mname\"]}\".'\n",
        "    )\n",
        "\n",
        "# Apply the function to each row and create a new column \"Example Description\"\n",
        "df['Example Description'] = df.apply(generate_description, axis=1)\n",
        "\n",
        "# Display the first few rows to verify the changes\n",
        "print(df[['Functional Description', 'Mname', 'Example Description']].head())\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file (optional)\n",
        "output_csv_file_path = 'output_file_with_descriptions.csv'\n",
        "df.to_csv(output_csv_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "46m_mVw5H7We"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}